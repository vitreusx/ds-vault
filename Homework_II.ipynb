{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework II",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VBJpAMzglRo"
      },
      "source": [
        "# RetinaMNIST with rotations\n",
        "\n",
        "In this exercise your goal will be to solve an object detection training and prediction task using the anchor-based approach.\n",
        "**As a part of your solution you should provide a report summarizing your findings and results of the conducted experiments.**\n",
        "\n",
        "##TLDR; overview\n",
        "\n",
        "In this task one should:\n",
        "- determine the size of the feasible anchors for the object detection task posed in this Assignment,\n",
        "- build an object detection model using the variant of `RetinaNet`,\n",
        "- prepare a matching suite which will match predicted anchors with ground truth bounding boxes,\n",
        "- train an object detection model using a variant of `RetinaLoss`.\n",
        "\n",
        "Hints and comments:\n",
        "\n",
        "- Model architecture and loss are heavily inspired by [RetinaNet](https://arxiv.org/pdf/1708.02002.pdf) paper,\n",
        "- you can freely subclass and extend the interface of classes in this exercise,\n",
        "- be sure that you understand the concept of an anchor for object detection, covered during the lecture about Object Detection. There are many great tutorials and articles about it (e.g. [this](https://towardsdatascience.com/anchor-boxes-the-key-to-quality-object-detection-ddf9d612d4f9) one, note however that we are not implementing ignoring boxes for simplicity).\n",
        "\n",
        "### Data description\n",
        "\n",
        "In this task we will paste bounding boxes with digits **from 1 to 5** randomly selected from `MNIST` dataset on a canvas of size `(128, 128)` and **randomly flipped by 90 degrees**. We assume that:\n",
        "\n",
        "- the two boxes from a canvas should have no more than `0.1` of `iou` overlap,\n",
        "- the digits are fully contained in canvas,\n",
        "- boxes are modeled using `MnistBox` class,\n",
        "- canvas is modeled using `MnistCanvas` class.\n",
        "\n",
        "Let us have a look at definition of these classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1rAdIiRq2G8"
      },
      "source": [
        "from typing import List\n",
        "from typing import Optional\n",
        "from typing import Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class MnistBox:\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        x_min: int,\n",
        "        y_min: int,\n",
        "        x_max: int,\n",
        "        y_max: int,\n",
        "        class_nb: Optional[int] = None,\n",
        "        rotated: Optional[bool] = None,\n",
        "    ):\n",
        "        self.x_min = x_min\n",
        "        self.x_max = x_max\n",
        "        self.y_min = y_min\n",
        "        self.y_max = y_max\n",
        "        self.class_nb = class_nb\n",
        "        self.rotated = rotated\n",
        "    \n",
        "    @property\n",
        "    def x_diff(self):\n",
        "        return self.x_max - self.x_min\n",
        "    \n",
        "    @property\n",
        "    def y_diff(self):\n",
        "        return self.y_max - self.y_min\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'Mnist Box: x_min = {self.x_min},' +\\\n",
        "               f' x_max = {self.x_max}, y_min = {self.y_min},' +\\\n",
        "               f' y_max = {self.y_max}. Class = {self.class_nb}.' +\\\n",
        "               f' Rotated = {self.rotated}.'\n",
        "\n",
        "    def plot_on_ax(self, ax, color: Optional[str] = 'r'):\n",
        "        ax.add_patch(\n",
        "            patches.Rectangle(\n",
        "                (self.y_min, self.x_min),\n",
        "                 self.y_diff,\n",
        "                 self.x_diff,\n",
        "                 linewidth=1,\n",
        "                 edgecolor=color,\n",
        "                 facecolor='none',\n",
        "            )\n",
        "        )\n",
        "        ax.text(\n",
        "            self.y_min,\n",
        "            self.x_min,\n",
        "            f'{self.class_nb}' if not self.rotated else f'{self.class_nb}*',\n",
        "            bbox={\"facecolor\": color, \"alpha\": 0.4},\n",
        "            clip_box=ax.clipbox,\n",
        "            clip_on=True,\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def area(self):\n",
        "        return max((self.x_max - self.x_min), 0) * max((self.y_max - self.y_min), 0)\n",
        "\n",
        "    def iou_with(self, other_box: \"MnistBox\"):\n",
        "        aux_box = MnistBox(\n",
        "            x_min=max(self.x_min, other_box.x_min),\n",
        "            x_max=min(self.x_max, other_box.x_max),\n",
        "            y_min=max(self.y_min, other_box.y_min),\n",
        "            y_max=min(self.y_max, other_box.y_max),\n",
        "        ) \n",
        "        return aux_box.area / (self.area + other_box.area - aux_box.area)\n",
        "\n",
        "\n",
        "class MnistCanvas:\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        image: np.ndarray,\n",
        "        boxes: List[MnistBox],\n",
        "    ):\n",
        "        self.image = image\n",
        "        self.boxes = boxes\n",
        "\n",
        "    def add_digit(\n",
        "        self,\n",
        "        digit: np.ndarray,\n",
        "        class_nb: int,\n",
        "        x_min: int,\n",
        "        y_min: int,\n",
        "        rotated=None,\n",
        "        iou_threshold=0.1,\n",
        "    ) -> bool:\n",
        "        \"\"\"\n",
        "        Add a digit to an image if it does not overlap with existing boxes\n",
        "        above iou_threshold.\n",
        "        \"\"\"\n",
        "        image_x, image_y = digit.shape\n",
        "        if x_min >= self.image.shape[0] and y_min >= self.image.shape[1]:\n",
        "            raise ValueError('Wrong initial corner box')\n",
        "        new_box_x_min = x_min\n",
        "        new_box_y_min = y_min\n",
        "        new_box_x_max = min(x_min + image_x, self.image.shape[0])\n",
        "        new_box_y_max = min(y_min + image_y, self.image.shape[1])\n",
        "        new_box = MnistBox(\n",
        "            x_min=new_box_x_min,\n",
        "            x_max=new_box_x_max,\n",
        "            y_min=new_box_y_min,\n",
        "            y_max=new_box_y_max,\n",
        "            class_nb=class_nb,\n",
        "            rotated=rotated,\n",
        "        )\n",
        "        old_background = self.image[\n",
        "            new_box_x_min:new_box_x_max,\n",
        "            new_box_y_min:new_box_y_max\n",
        "        ]\n",
        "        for box in self.boxes:\n",
        "            if new_box.iou_with(box) > iou_threshold:\n",
        "                return False\n",
        "        self.image[\n",
        "            new_box_x_min:new_box_x_max,\n",
        "            new_box_y_min:new_box_y_max\n",
        "        ] = np.maximum(old_background, digit)\n",
        "        self.boxes.append(\n",
        "            new_box\n",
        "        ) \n",
        "        return True\n",
        "        \n",
        "    def get_torch_tensor(self) -> torch.Tensor:\n",
        "        np_image = self.image.astype('float32')\n",
        "        np_image = np_image.reshape(\n",
        "            (1, 1, self.image.shape[0], self.image.shape[1])\n",
        "        )\n",
        "        return torch.from_numpy(np_image).to(DEVICE)\n",
        "\n",
        "    @classmethod\n",
        "    def get_empty_of_size(cls, size: Tuple[int, int]):\n",
        "        return cls(\n",
        "            image=np.zeros(size),\n",
        "            boxes=[],\n",
        "        )\n",
        "\n",
        "    def plot(self, boxes: Optional[List[MnistBox]] = None):\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.imshow(self.image)\n",
        "        boxes = boxes or self.boxes\n",
        "        for box in boxes:\n",
        "            box.plot_on_ax(ax)\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWMxgsgFtlze"
      },
      "source": [
        "Each canvas has 3-6 boxes with randomly selected digits. The digits for training data are from first 10K examples from `MNIST` train data. The digits for test data are selected from first 1K examples from `MNIST` test data. The Dataset is generated using the following functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HezSZXw4z-cx"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "mnist_data = mnist.load_data()\n",
        "(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = mnist_data\n",
        "\n",
        "\n",
        "def crop_insignificant_values(digit:np.ndarray, threshold=0.1):\n",
        "    bool_digit = digit > threshold\n",
        "    x_range = bool_digit.max(axis=0)\n",
        "    y_range = bool_digit.max(axis=1)\n",
        "    start_x = (x_range.cumsum() == 0).sum()\n",
        "    end_x = (x_range[::-1].cumsum() == 0).sum()\n",
        "    start_y = (y_range.cumsum() == 0).sum()\n",
        "    end_y = (y_range[::-1].cumsum() == 0).sum()\n",
        "    return digit[start_y:-end_y - 1, start_x:-end_x - 1]\n",
        "\n",
        "\n",
        "TRAIN_DIGITS = [\n",
        "    crop_insignificant_values(digit) / 255.0\n",
        "    for digit_index, digit in enumerate(mnist_x_train[:10000])\n",
        "]\n",
        "TRAIN_CLASSES = mnist_y_train[:10000]\n",
        "\n",
        "TEST_DIGITS = [\n",
        "    crop_insignificant_values(digit) / 255.0\n",
        "    for digit_index, digit in enumerate(mnist_x_test[:1000])\n",
        "]\n",
        "TEST_CLASSES = mnist_y_test[:1000]\n",
        "\n",
        "\n",
        "def get_random_canvas(\n",
        "    digits: Optional[List[np.ndarray]] = None,\n",
        "    classes: Optional[List[int]] = None,\n",
        "    nb_of_digits: Optional[int] = None,\n",
        "    ):\n",
        "    digits = digits if digits is not None else TRAIN_DIGITS\n",
        "    classes = classes if classes is not None else TRAIN_CLASSES\n",
        "    nb_of_digits = nb_of_digits if nb_of_digits is not None else np.random.randint(low=3, high=6 + 1)\n",
        "    new_canvas = MnistCanvas.get_empty_of_size(size=(128, 128))\n",
        "    attempts_done = 0\n",
        "    while attempts_done < nb_of_digits:\n",
        "        current_digit_index = np.random.randint(len(digits))\n",
        "        current_digit_class = classes[current_digit_index]\n",
        "        if current_digit_class not in [1, 2, 3, 4, 5]:\n",
        "            continue\n",
        "        rotate = np.random.random() > 0.5\n",
        "        current_digit = digits[current_digit_index]\n",
        "        if rotate:\n",
        "            current_digit = np.rot90(current_digit)\n",
        "        random_x_min = np.random.randint(0, 128 - current_digit.shape[0] - 3)\n",
        "        random_y_min = np.random.randint(0, 128 - current_digit.shape[1] - 3)\n",
        "        if new_canvas.add_digit(\n",
        "            digit=current_digit,\n",
        "            x_min=random_x_min,\n",
        "            y_min=random_y_min,\n",
        "            class_nb=current_digit_class,\n",
        "            rotated=rotate,\n",
        "        ):\n",
        "            attempts_done += 1\n",
        "    return new_canvas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i2OjUEC7eaC"
      },
      "source": [
        "Let us have a look at example canvas (rotated digits have additional *added to description)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "OsLpINOtvhd8",
        "outputId": "91e68414-3f34-4f78-b2e8-fd944c45db39"
      },
      "source": [
        "mnist_canvas = get_random_canvas()\n",
        "mnist_canvas.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QkpHGiOCnng"
      },
      "source": [
        "Now - let us generate test canvas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "PV410KSYC-eT",
        "outputId": "61627aca-9cc9-4235-a0e8-cfca22cb06aa"
      },
      "source": [
        "TEST_CANVAS_SIZE = 256\n",
        "TEST_SEED = 42 # DO NOT CHANGE THIS LINE.\n",
        "\n",
        "np.random.seed(TEST_SEED)\n",
        "\n",
        "TEST_CANVAS = [\n",
        "    get_random_canvas(\n",
        "        digits=TEST_DIGITS,\n",
        "        classes=TEST_CLASSES,\n",
        "    )\n",
        "    for _ in range(TEST_CANVAS_SIZE)\n",
        "]\n",
        "\n",
        "TEST_CANVAS[0].plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgU2bKyJ3pVh"
      },
      "source": [
        "For training one can either:\n",
        "- generate `TRAIN_CANVAS` similarly to `TEST_CANVAS` creation,\n",
        "- use the fact that `get_random_canvas()` generates a random train canvas and generate training data on-the-fly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri3Jh7GzjZ4W"
      },
      "source": [
        "### Anchor size analysis (2pts)\n",
        "\n",
        "For this task:\n",
        "1. Sample at least 1000 random canvas.\n",
        "2. Analyze the sizes (heights and widths) of the `MnistBox`es from this canvas.\n",
        "3. Select the anchor sizes which will match the problem the best.\n",
        "\n",
        "Selected anchor sizes should be stored in a sensible manner in `ANCHOR_SIZES` list."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution\n",
        "\n",
        "I thought that it may be a good idea to look at a heatmap of the anchor sizes."
      ],
      "metadata": {
        "id": "-YpjeUB9XAEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CANVASES = 1000\n",
        "\n",
        "canvases = [get_random_canvas(digits=TRAIN_DIGITS, classes=TRAIN_CLASSES)\n",
        "            for _ in range(NUM_CANVASES)]\n",
        "boxes = [box for canvas in canvases for box in canvas.boxes]\n",
        "box_sizes = np.array([[box.x_diff, box.y_diff] for box in boxes])"
      ],
      "metadata": {
        "id": "aYsz2q6LXK4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LogNorm\n",
        "\n",
        "x_max, y_max = np.amax(box_sizes, axis=0)\n",
        "counter = np.zeros((x_max+1, y_max+1), dtype=int)\n",
        "np.add.at(counter, (box_sizes[:,0], box_sizes[:,1]), 1)\n",
        "\n",
        "plt.imshow(counter, norm=LogNorm())\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "vp-bYaRyX0tL",
        "outputId": "4e908367-618d-403e-e028-45172f43fca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f9051639490>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all(x == 19 or y == 19 for x, y in box_sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GXkgu4tdROa",
        "outputId": "4decf2bf-4da5-46ba-a3bd-dfd5b48568a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It would indeed seem that at least one of the coordinates is equal to $19$; I would therefore say that the appropriate anchor sizes are $(x, 19)$ for odd $x \\in \\{x_{\\min}, \\ldots, x_{\\max}\\}$ and likewise $(19, y)$ (the \"odd\" part is to make it easier to produce the anchors, and besides it reduces the number of them by 2x). I will also make it a bit more sparse in the low end since there aren't that many box sizes there, as is clear from the heatmap."
      ],
      "metadata": {
        "id": "ADkOki7IdNP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_min, y_min = np.amin(box_sizes, axis=0)\n",
        "print(x_min, x_max, y_min, y_max)\n",
        "\n",
        "values = [3, 7, 11, 13, 15, 17, 19]\n",
        "ANCHOR_SIZES = [*((x, 19) for x in values), \n",
        "                *((19, y) for y in values)]\n",
        "ANCHOR_SIZES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5YoTIEjeRm2",
        "outputId": "0e5a6323-e114-416e-d041-38fe4d4f76a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 19 2 19\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(3, 19),\n",
              " (7, 19),\n",
              " (11, 19),\n",
              " (13, 19),\n",
              " (15, 19),\n",
              " (17, 19),\n",
              " (19, 19),\n",
              " (19, 3),\n",
              " (19, 7),\n",
              " (19, 11),\n",
              " (19, 13),\n",
              " (19, 15),\n",
              " (19, 17),\n",
              " (19, 19)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GpJZUkDGJSi"
      },
      "source": [
        "### Model building (2pt)\n",
        "\n",
        "\n",
        "One should build a model for digit detection in $\\texttt{pytorch}$. Model should consist of:\n",
        "\n",
        "#### $\\texttt{backbone}$:\n",
        "\n",
        "We provided you with a backbone model architecture that accepts a `MnistCanvas` instance and output a tensor with shape $(1, 16, 16, 128)$. It should be trained together with the rest of your solution.\n",
        "\n",
        "#### $\\texttt{anchors}$:\n",
        "\n",
        "List of `MnistBox`es where each box:\n",
        "\n",
        "- should have size of one of selected `ANCHOR_SIZES`,\n",
        "- should have center coordinates on canvas of type $\\left(\\left(m + \\frac{1}{2}\\right) * 8, \\left(n + \\frac{1}{2}\\right) * 8\\right)$  for $m, n \\in \\{0, 1, \\dots, 16 - 1\\}$,\n",
        "\n",
        "`MnistBox` with anchor should have an attribute `class_nb` set to `None`.\n",
        "\n",
        "#### $\\texttt{digitClassificationHead}$:\n",
        "\n",
        "$\\texttt{digitClassificationHead}$ should accept backbone output as an input and output `digit_classification_output` tensor of shape $(len(\\texttt{anchors)}, 5)$ where the value $ch_{i, j}$ which is the value of i-th row and j-th column has a property that $sigmoid(ch_{i, j})$ is a probability that i-th anchor from $\\texttt{anchors}$ overlaps significantly with some canvas `GTBox: MnistBox` with a digit of class $j + 1$ (ground truth box).\n",
        "\n",
        "#### $\\texttt{rotationClassificationHead}$:\n",
        "\n",
        "$\\texttt{rotationClassificationHead}$ should accept backbone output as an input and output `rotation_classification_output` tensor of shape $(len(\\texttt{anchors)}, 2)$ where the value $ch_{i, j}$ which is the value of i-th row and j-th column has a property that $sigmoid(ch_{i, j})$ is a probability that i-th anchor from $\\texttt{anchors}$ overlaps significantly with some canvas `GTBox: MnistBox` with a digit which was not rotated when $j = 0$ and was rotated when $j = 1$.\n",
        "\n",
        "#### $\\texttt{boxRegressionHead}$:\n",
        "\n",
        "$\\texttt{boxRegressionHead}$ should accept backbone output as an input and output `box_regression_output` tensor of shape $(len(\\texttt{anchors)}, 4)$ where the value $br_{i}$ which is the value of i-th row has a property that if there is a ground truth digit box $\\texttt{GTBox}$ - significantly overlapping with $\\texttt{anchor}[i]$ then the following properties hold:\n",
        "\n",
        "$$\\texttt{GTBox.x_min} = \\texttt{anchor[i].x_min} + br_{i, 0},$$ \n",
        "$$\\texttt{GTBox.x_max} = \\texttt{anchor[i].x_max} + br_{i, 1},$$ \n",
        "$$\\texttt{GTBox.y_min} = \\texttt{anchor[i].y_min} + br_{i, 2},$$ \n",
        "$$\\texttt{GTBox.y_max} = \\texttt{anchor[i].y_max} + br_{i, 3}.$$ \n",
        "\n",
        "#### *Hint*: be careful with a construction of a head output as a simple reshaping might cause unexpected permutation of anchors.\n",
        "\n",
        "### Model output\n",
        "\n",
        "Model should output `DigitDetectionModelOutput` class defined below.\n",
        "\n",
        "#### Comment on _significant overlap_:\n",
        "\n",
        "The meaning of significant overlap will be described later."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution\n",
        "\n",
        "Let's start with the anchors. I will clip some of them, so not all the centers will be as specified in the text above, but I hope it's not a major issue."
      ],
      "metadata": {
        "id": "oWVGbcmUz78q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_box(m, n, x, y):\n",
        "  x_min = np.clip(8*m+4-x//2, 0, 128-1)\n",
        "  x_max = np.clip(8*m+4+x//2, 0, 128-1)\n",
        "  y_min = np.clip(8*n+4-y//2, 0, 128-1)\n",
        "  y_max = np.clip(8*n+4+y//2, 0, 128-1)\n",
        "  return MnistBox(x_min, y_min, x_max, y_max)\n",
        "\n",
        "ms, ns = np.indices((16, 16))\n",
        "ANCHORS = np.array([[make_box(ms[idx], ns[idx], x, y)\n",
        "                     for x, y in ANCHOR_SIZES]\n",
        "                    for idx in np.ndindex(*ms.shape)])\n",
        "ANCHORS = ANCHORS.reshape((-1))"
      ],
      "metadata": {
        "id": "9h1WW9rs5QJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the `MaxPool`ing in the backbone makes it so that the 16x16 \"image\" produced by it roughly corresponds to the anchor centers that we want (in any case, that's what we shall assume since it makes it easier). Then, insofar as the heads are concerned, we just use a `Conv2d` from the output # of channels from the backbone to 5, 2, 4 channels for the heads respectively, with a kernel size of 1 since we don't want to pool anything at this stage but rather just reduce it all, sort of like a bunch of fully-connected layers for each of the segments. Finally we flatten the tensors in the same fashion as we do the `ANCHORS`, so that we end up with the correct order of anchors (hopefully)."
      ],
      "metadata": {
        "id": "S0MroqPO5PlL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXco8riNGHhl"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "\n",
        "class DigitDetectionModelOutput:\n",
        "    def __init__(\n",
        "        self,\n",
        "        anchors: List[MnistBox],\n",
        "        digit_classification_output: torch.Tensor,\n",
        "        rotation_classification_output: torch.Tensor,\n",
        "        box_regression_output: torch.Tensor,\n",
        "    ):\n",
        "        self.anchors = anchors\n",
        "        self.digit_classification_output = digit_classification_output\n",
        "        self.box_regression_output = box_regression_output\n",
        "        self.rotation_classification_output = rotation_classification_output\n",
        "\n",
        "\n",
        "class Backbone(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.output_shape = (16, 16, 128)\n",
        "        self.first_block = torch.nn.Sequential(\n",
        "            nn.Conv2d(1, 16, (3, 3), padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, (3, 3), padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "        self.blocks = torch.nn.ModuleList(\n",
        "            [torch.nn.Sequential(*[\n",
        "                nn.Conv2d(16 * (2 ** i), 16 * (2 ** (i + 1)), (3, 3), padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(2, 2),\n",
        "              ]) for i in range(1, 3)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def forward(self, x: MnistCanvas) -> torch.Tensor:\n",
        "        image = torch.Tensor(x.image).to(DEVICE).view(1, 1, 128, 128)\n",
        "        aux = self.first_block(image)\n",
        "        for block in self.blocks:\n",
        "            aux = block(aux)\n",
        "        return aux\n",
        "\n",
        "\n",
        "class DigitDetectionModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.backbone = Backbone()\n",
        "    self.num_anchors = len(ANCHOR_SIZES)\n",
        "\n",
        "    def create_head(out_channels, classifier=True):\n",
        "      final_conv = nn.Conv2d(128, out_channels, 1)\n",
        "      if classifier:\n",
        "        def_prob = 1e-2\n",
        "        final_conv.bias.data.fill_(-np.log((1-def_prob)/def_prob))\n",
        "      \n",
        "      return torch.nn.Sequential(\n",
        "        nn.Conv2d(128, 128, 3, padding=1),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(128, 128, 3, padding=1),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(128, 128, 3, padding=1),\n",
        "        nn.ReLU(True),\n",
        "        final_conv\n",
        "      )\n",
        "\n",
        "    self.digit_pred_head = create_head(5*self.num_anchors)\n",
        "    self.rot_pred_head = create_head(2*self.num_anchors)\n",
        "    self.box_regr_head = create_head(4*self.num_anchors, classifier=False)\n",
        "\n",
        "  def forward(self, x: MnistCanvas) -> DigitDetectionModelOutput:\n",
        "    x = self.backbone(x)\n",
        "\n",
        "    anchors = ANCHORS\n",
        "\n",
        "    digit_pred = self.digit_pred_head(x)\n",
        "    digit_pred = digit_pred.permute((0, 2, 3, 1)).reshape((len(anchors), 5))\n",
        "\n",
        "    rot_pred = self.rot_pred_head(x)\n",
        "    rot_pred = rot_pred.permute((0, 2, 3, 1)).reshape((len(anchors), 2))\n",
        "\n",
        "    box_regr = self.box_regr_head(x)\n",
        "    box_regr = box_regr.permute((0, 2, 3, 1)).reshape((len(anchors), 4))\n",
        "\n",
        "    return DigitDetectionModelOutput(ANCHORS, digit_pred, rot_pred, box_regr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnZu3sdhTfTJ"
      },
      "source": [
        "### Significant overlap (4pt)\n",
        "\n",
        "In order to manage definition of a _significant overlap_ student should implement the `TargetDecoder`. `TargetDecoder` have two methods:\n",
        "\n",
        "### - `get_targets`\n",
        "\n",
        "This method accepts a `canvas: MnistCanvas` with boxes later refered to as `gt_boxes: List[MnistBox]`, `anchors: List[MnistBox]` of model anchors and `iou_threshold: float`. Its output should be `DigitDetectionModelTarget` instance with the following attributes:\n",
        "\n",
        "- `digit_classification_target` - a tensor of shape $(len(anchors), 5)$,\n",
        "- `rotation_classification_target` - a tensor of shape $(len(anchors), 2)$\n",
        "- `box_regression_target` - a tensor of shape $(len(anchors), 4)$,\n",
        "- `matched_anchors` - a list of indices anchors matched (see definition below).\n",
        "\n",
        "The output attributes should be computed in a following manner: \n",
        "\n",
        "1. All of the outputs of the output tensors should be `0` except the case presented in the point 2.\n",
        "1. if for anchor `anchors[i]` there exist at least one `gt_box` from `gt_boxes` with `iou` overlap greater than `iou_threshold` then let `gt_best` be the one with the greatest `iou` overlap (ties resolved randomly). Then `box_regression_target` should encode the bounding box correction, namely:\n",
        "\n",
        "$$\\texttt{box_regression_target}[i, 0] = \\texttt{gt_best.x_min} - \\texttt{anchor[i].x_min}$$ \n",
        "$$\\texttt{box_regression_target}[i, 1] = \\texttt{gt_best.x_max} - \\texttt{anchor[i].x_max}$$ \n",
        "$$\\texttt{box_regression_target}[i, 2] = \\texttt{gt_best.y_min} - \\texttt{anchor[i].y_min}$$ \n",
        "$$\\texttt{box_regression_target}[i, 3] = \\texttt{gt_best.y_max} - \\texttt{anchor[i].y_max}$$,\n",
        "\n",
        "`digit_classification_target` should encode the class of matched `gt_best`, namely:\n",
        "\n",
        "$$\\texttt{digit_classification_target}[i, \\texttt{gt_best.class_nb} - 1] = 1.$$\n",
        "\n",
        "`rotation_classification_target` should encode if matched `gt_best` has a digit which was rotated, namely:\n",
        "\n",
        "$$\\texttt{rotation_classification_target}[i, 0] = 1,$$\n",
        "\n",
        "if `gt_best` digit was not rotated and:\n",
        "\n",
        "$$\\texttt{rotation_classification_target}[i, 1] = 1,$$\n",
        "\n",
        "if `gt_best` digit was rotated (this might be interpreted as a one-hot encoding if a digit was rotated).\n",
        "\n",
        "Moreover - the `anchor[i]` is considered to be _matched_ with some ground truth box so index `i` should be in `matched_anchors` list.\n",
        "\n",
        "The output should be packed into `DigitDetectionModelTarget` class defined below.\n",
        "\n",
        "_Hint_: note that there might be cases when no anchor is matched. What does it mean about your anchors?\n",
        "\n",
        "### - `get_predictions`\n",
        "\n",
        "This method should decode the `DigitDetectionModelOutput` to set of final boxes\n",
        "predictions. We leave the way of selecting the predictions to students.\n",
        "\n",
        "_HINT_: we definitely advise to use `torchvision.ops.nms` function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ANCHORS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68aO6tCZKOOy",
        "outputId": "22689b81-85e8-4c3f-d067-102ede0f24ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([Mnist Box: x_min = 3, x_max = 5, y_min = 0, y_max = 13. Class = None. Rotated = None.,\n",
              "       Mnist Box: x_min = 1, x_max = 7, y_min = 0, y_max = 13. Class = None. Rotated = None.,\n",
              "       Mnist Box: x_min = 0, x_max = 9, y_min = 0, y_max = 13. Class = None. Rotated = None.,\n",
              "       ...,\n",
              "       Mnist Box: x_min = 115, x_max = 127, y_min = 117, y_max = 127. Class = None. Rotated = None.,\n",
              "       Mnist Box: x_min = 115, x_max = 127, y_min = 116, y_max = 127. Class = None. Rotated = None.,\n",
              "       Mnist Box: x_min = 115, x_max = 127, y_min = 115, y_max = 127. Class = None. Rotated = None.],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWcthFZQquNo"
      },
      "source": [
        "from torchvision.ops import box_iou, nms\n",
        "\n",
        "\n",
        "CONFIDENCE_THRESHOLD = 0.7\n",
        "MAX_OVERLAP_IOU = 0.1\n",
        "\n",
        "ANCHOR_BOXES = torch.tensor([[a.x_min, a.y_min, a.x_max, a.y_max] \n",
        "                              for a in ANCHORS]).float()\n",
        "\n",
        "class DigitDetectionModelTarget:\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        digit_classification_target: torch.Tensor,\n",
        "        rotation_classification_target: torch.Tensor,\n",
        "        box_regression_target: torch.Tensor,\n",
        "        matched_anchors: List[int],\n",
        "    ):\n",
        "        self.digit_classification_target = digit_classification_target\n",
        "        self.rotation_classification_target = rotation_classification_target\n",
        "        self.box_regression_target = box_regression_target\n",
        "        self.matched_anchors = matched_anchors\n",
        "\n",
        "\n",
        "class TargetDecoder:\n",
        "\n",
        "    def get_targets(\n",
        "        self,\n",
        "        canvas: MnistCanvas,\n",
        "        anchors: List[MnistBox],\n",
        "        iou_threshold: float=0.2,\n",
        "        nb_of_classes: int = 5,\n",
        "    ) -> DigitDetectionModelTarget:\n",
        "      digit_classif_tgt = torch.zeros(len(anchors), nb_of_classes)\n",
        "      rot_classif_tgt = torch.zeros(len(anchors), 2)\n",
        "      box_regr_tgt = torch.zeros(len(anchors), 4)\n",
        "      matched_anchors = []\n",
        "\n",
        "      gt_boxes = canvas.boxes\n",
        "      if len(gt_boxes) > 0:\n",
        "        for idx, anchor in enumerate(anchors):\n",
        "          gt_best = max(gt_boxes, key=anchor.iou_with)\n",
        "          if anchor.iou_with(gt_best) > iou_threshold:\n",
        "            digit_classif_tgt[idx,gt_best.class_nb-1] = 1\n",
        "            rot_classif_tgt[idx,1 if gt_best.rotated else 0] = 1\n",
        "            box_regr_tgt[idx,0] = gt_best.x_min - anchor.x_min\n",
        "            box_regr_tgt[idx,1] = gt_best.y_min - anchor.y_min\n",
        "            box_regr_tgt[idx,2] = gt_best.x_max - anchor.x_max\n",
        "            box_regr_tgt[idx,3] = gt_best.y_max - anchor.y_max\n",
        "            matched_anchors.append(idx)\n",
        "\n",
        "      return DigitDetectionModelTarget(digit_classif_tgt, rot_classif_tgt,\n",
        "                                       box_regr_tgt, matched_anchors)\n",
        "\n",
        "    def get_predictions(\n",
        "        self,\n",
        "        model_output: DigitDetectionModelOutput,\n",
        "    ) -> List[MnistBox]:\n",
        "        probs = torch.sigmoid(model_output.digit_classification_output)\n",
        "        max_probs = torch.amax(probs, 1)\n",
        "        anchor_hits, = torch.where(max_probs > CONFIDENCE_THRESHOLD)\n",
        "        sel_anchors = nms(ANCHOR_BOXES[anchor_hits].to(DEVICE), max_probs[anchor_hits],\n",
        "                          MAX_OVERLAP_IOU)\n",
        "        \n",
        "        digits = torch.argmax(probs[sel_anchors], 1)\n",
        "        \n",
        "        rot_probs = torch.sigmoid(model_output.rotation_classification_output[sel_anchors])\n",
        "        is_rotated = torch.argmax(rot_probs, 1).bool()\n",
        "\n",
        "        box_regr = model_output.box_regression_output[sel_anchors]\n",
        "        \n",
        "        def prediction_box(idx):\n",
        "          anchor = ANCHORS[sel_anchors[idx]]\n",
        "          x_min = anchor.x_min + box_regr[idx,0]\n",
        "          y_min = anchor.y_min + box_regr[idx,1]\n",
        "          x_max = anchor.x_max + box_regr[idx,2]\n",
        "          y_max = anchor.y_max + box_regr[idx,3]\n",
        "          return MnistBox(x_min, y_min, x_max, y_max, digits[idx], is_rotated[idx])\n",
        "\n",
        "        return [prediction_box(idx) for idx in range(len(sel_anchors))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA1Nvz6jagyP"
      },
      "source": [
        "### Metrics (4pt)\n",
        "\n",
        "## Retina Loss\n",
        "As a loss function one should implement the variant of Retina Loss. It should be computed in a following manner:\n",
        "\n",
        "`compute_loss`: \n",
        "\n",
        "This method accepts:\n",
        "- `DigitDetectionModelTarget`,\n",
        "- `DigitDetectionModelOutput`,\n",
        "\n",
        "and computes a loss which is a sum of a:\n",
        "- `torch.nn.SmoothL1Loss` between boxes predictions and targets averaged only over matched anchors,\n",
        "- `torchvision.ops.sigmoid_focal_loss` between digit predictions and targets,\n",
        "- `torchvision.ops.sigmoid_focal_loss` between rotation predictions and targets,\n",
        "\n",
        "One can either use `torch` default parameters for this losses or try to tune them.\n",
        "\n",
        "If there are no matched anchors - a loss should return `None`. Remember to handle this case separately in your training loop. What does the occurence of this case means about your anchors?\n",
        "\n",
        "## Digit Accuracy\n",
        "\n",
        "This method shoud accept `canvas: MnistCanvas` and `predicted_boxes: List[MnistBox]` obtained using `TargetDecoder.get_predictions` method and output whether there is a direct matching between boxes from `MnistCanvas` and predictions. There is a direct matching if:\n",
        "\n",
        "- for all boxes from `canvas`, there exist precisely one box from `predicted_boxes` with a matching class  and `iou` overlap greater than `0.5`,\n",
        "- the number of `canvas` boxes match `len(predicted_boxes)`.\n",
        "\n",
        "The model shoud output `1` if there is a matching and `0` otherwise.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rffXn9CQwVu4"
      },
      "source": [
        "import torch\n",
        "import torchvision \n",
        "\n",
        "\n",
        "class RetinaLoss:\n",
        "    def compute_loss(\n",
        "        self,\n",
        "        model_output: DigitDetectionModelOutput,\n",
        "        model_target: DigitDetectionModelTarget,\n",
        "    ) -> Optional[torch.Tensor]:\n",
        "      \n",
        "      matched = model_target.matched_anchors\n",
        "      if len(matched) > 0:\n",
        "        loss = 0.0\n",
        "\n",
        "        pred_regr_box = model_output.box_regression_output[matched].to(DEVICE)\n",
        "        true_regr_box = model_target.box_regression_target[matched].to(DEVICE)\n",
        "        loss += torch.nn.SmoothL1Loss()(pred_regr_box, true_regr_box)\n",
        "\n",
        "        pred_digits = model_output.digit_classification_output.to(DEVICE)\n",
        "        true_digits = model_target.digit_classification_target.to(DEVICE)\n",
        "        loss += torchvision.ops.sigmoid_focal_loss(pred_digits, true_digits, reduction=\"mean\")\n",
        "\n",
        "        pred_rot = model_output.rotation_classification_output.to(DEVICE)\n",
        "        true_rot = model_target.rotation_classification_target.to(DEVICE)\n",
        "        loss += torchvision.ops.sigmoid_focal_loss(pred_rot, true_rot, reduction=\"mean\")\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "class DigitAccuracy:\n",
        "    def compute_metric  (\n",
        "        self,\n",
        "        predicted_boxes: List[MnistBox],\n",
        "        canvas: MnistCanvas,\n",
        "    ):\n",
        "        if len(canvas.boxes) != len(predicted_boxes):\n",
        "          return 0\n",
        "        \n",
        "        for gt_box in canvas.boxes:\n",
        "          num_matching = 0\n",
        "          for pred_box in predicted_boxes:\n",
        "            if gt_box.class_nb == pred_box.class_nb and gt_box.iou_with(pred_box) > 0.5:\n",
        "              num_matching += 1\n",
        "          \n",
        "          if num_matching != 1:\n",
        "            return 0\n",
        "        \n",
        "        return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15n5w-hhvRbS"
      },
      "source": [
        "### Train your model (4pt)\n",
        "\n",
        "One should use all classes defined above to train the model.\n",
        "\n",
        "A passing threshold is `10%` of a `DigitAccuracy` on a `TEST_CANVAS` data.\n",
        "\n",
        "Plot example results of matched and mismatched predictions (2pt).\n",
        "\n",
        "**Hint:** Training can take a while to achieve the expected accuracy. It is normal that for many epochs at the beginning accuracy is constantly $0$. Do not worry as long as the loss is on average decreasing across epochs.\n",
        "\n",
        "Have fun!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution\n",
        "So, uhm.. I guess it seems to work fine in that the loss is decreasing, but it takes a long time and I sort-of didn't have it. Oh well."
      ],
      "metadata": {
        "id": "Y2ltORuIEKwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko4JMQZp-mem",
        "outputId": "feab761f-8de3-4f77-abae-ec63ae3613f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /home/vitreus/.local/lib/python3.8/site-packages (4.62.3)\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "CANVASES_PER_EPOCH = 2048\n",
        "NUM_EPOCHS = 25\n",
        "LAST_EPOCH = 8\n",
        "\n",
        "TRAIN_CANVASES = [get_random_canvas(digits=TRAIN_DIGITS, classes=TRAIN_CLASSES)\n",
        "                  for _ in range(CANVASES_PER_EPOCH)]\n",
        "\n",
        "net = DigitDetectionModel()\n",
        "net = net.to(DEVICE)\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
        "target_decoder = TargetDecoder()\n",
        "retina_loss = RetinaLoss()\n",
        "digit_acc = DigitAccuracy()\n",
        "\n",
        "def train(epoch_idx):\n",
        "  net.train()\n",
        "  train_loss = 0.0\n",
        "  num_items = 0\n",
        "  pbar = tqdm(TRAIN_CANVASES)\n",
        "  for idx, canvas in enumerate(pbar):\n",
        "    optimizer.zero_grad()\n",
        "    output = net.forward(canvas)\n",
        "    targets = target_decoder.get_targets(canvas, output.anchors)\n",
        "    loss = retina_loss.compute_loss(output, targets)\n",
        "    if loss is not None:\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss += loss.item()\n",
        "      num_items += 1\n",
        "    pbar.set_description(f\"train | epoch {epoch_idx}, {idx}/{len(TRAIN_CANVASES)}, loss = {train_loss/num_items}\")\n",
        "\n",
        "def test(epoch_idx):\n",
        "  net.eval()\n",
        "  test_loss = 0.0\n",
        "  test_acc = 0\n",
        "  num_items = 0\n",
        "  pbar = tqdm(TEST_CANVAS)\n",
        "  for idx, canvas in enumerate(pbar):\n",
        "    output = net.forward(canvas)\n",
        "    \n",
        "    targets = target_decoder.get_targets(canvas, output.anchors)\n",
        "    loss = retina_loss.compute_loss(output, targets)\n",
        "    if loss is not None:\n",
        "      test_loss += loss.item()\n",
        "    \n",
        "    predictions = target_decoder.get_predictions(output)\n",
        "    is_correct = digit_acc.compute_metric(predictions, canvas)\n",
        "    test_acc += is_correct\n",
        "\n",
        "    num_items += 1\n",
        "    pbar.set_description(f\"test | epoch {epoch_idx}, {idx}/{len(TEST_CANVAS)}, loss = {test_loss/num_items}, acc = {test_acc/num_items}\")\n",
        "\n",
        "def main():\n",
        "  start_epoch = 0\n",
        "  if LAST_EPOCH is not None:\n",
        "    net.load_state_dict(torch.load(f'net{LAST_EPOCH}'))\n",
        "    start_epoch = LAST_EPOCH + 1\n",
        "\n",
        "  for epoch_idx in range(start_epoch, NUM_EPOCHS):\n",
        "    train(epoch_idx)\n",
        "    test(epoch_idx)\n",
        "    torch.save(net.state_dict(), f'net{epoch_idx}')"
      ],
      "metadata": {
        "id": "crAiOsxgZ3Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "mRI-_q1UA4rk",
        "outputId": "b33fc887-2850-4624-d9eb-a7f530e57c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train | epoch 9, 2047/2048, loss = 0.24401087132446264: 100%|██████████| 2048/2048 [05:48<00:00,  5.88it/s]\n",
            "test | epoch 9, 255/256, loss = 0.24009239692531992, acc = 0.0: 100%|██████████| 256/256 [00:41<00:00,  6.21it/s]\n",
            "train | epoch 10, 2047/2048, loss = 0.2163629024380498: 100%|██████████| 2048/2048 [05:48<00:00,  5.88it/s]\n",
            "test | epoch 10, 255/256, loss = 0.22881385558866896, acc = 0.0: 100%|██████████| 256/256 [00:41<00:00,  6.21it/s]\n",
            "train | epoch 11, 2047/2048, loss = 0.19584992685122415: 100%|██████████| 2048/2048 [05:48<00:00,  5.88it/s]\n",
            "test | epoch 11, 255/256, loss = 0.21799024631036445, acc = 0.0: 100%|██████████| 256/256 [00:41<00:00,  6.21it/s]\n",
            "train | epoch 12, 2047/2048, loss = 0.1791528681633281: 100%|██████████| 2048/2048 [05:48<00:00,  5.88it/s]\n",
            "test | epoch 12, 255/256, loss = 0.21013509909971617, acc = 0.0: 100%|██████████| 256/256 [00:41<00:00,  6.22it/s]\n",
            "train | epoch 13, 2047/2048, loss = 0.16484398883585527: 100%|██████████| 2048/2048 [05:47<00:00,  5.89it/s]\n",
            "test | epoch 13, 255/256, loss = 0.20314071750908624, acc = 0.0: 100%|██████████| 256/256 [00:41<00:00,  6.21it/s]\n",
            "train | epoch 14, 2047/2048, loss = 0.15227977563245076: 100%|██████████| 2048/2048 [05:48<00:00,  5.87it/s]\n",
            "test | epoch 14, 255/256, loss = 0.19776028854539618, acc = 0.0: 100%|██████████| 256/256 [00:41<00:00,  6.21it/s]\n",
            "train | epoch 15, 2047/2048, loss = 0.14125642782073555: 100%|██████████| 2048/2048 [05:48<00:00,  5.88it/s]\n",
            "test | epoch 15, 255/256, loss = 0.19386219029547647, acc = 0.0: 100%|██████████| 256/256 [00:41<00:00,  6.21it/s]\n",
            "train | epoch 16, 2047/2048, loss = 0.1316381513579472: 100%|██████████| 2048/2048 [05:48<00:00,  5.87it/s]\n",
            "test | epoch 16, 255/256, loss = 0.1900004211202031, acc = 0.0: 100%|██████████| 256/256 [00:41<00:00,  6.19it/s]\n",
            "train | epoch 17, 21/2048, loss = 0.1191750295798887:   1%|          | 22/2048 [00:04<06:13,  5.42it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-7b9385cd586f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'net{epoch_idx}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-7b9385cd586f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch_idx)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretina_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-86f37bdbc292>\u001b[0m in \u001b[0;36mget_targets\u001b[0;34m(self, canvas, anchors, iou_threshold, nb_of_classes)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m           \u001b[0mgt_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manchor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miou_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m           \u001b[0;32mif\u001b[0m \u001b[0manchor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miou_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_best\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mdigit_classif_tgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_nb\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mrot_classif_tgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgt_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotated\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-956655190171>\u001b[0m in \u001b[0;36miou_with\u001b[0;34m(self, other_box)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miou_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_box\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"MnistBox\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         aux_box = MnistBox(\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mx_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mx_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_decoder.get_predictions(net(TEST_CANVAS[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxE8iXPjGgYZ",
        "outputId": "3f48f843-db81-42e3-a8fe-6bb39b5e58bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Mnist Box: x_min = -0.05280116945505142, x_max = 12.374776840209961, y_min = 12.169018745422363, y_max = 29.583669662475586. Class = 3. Rotated = True.,\n",
              " Mnist Box: x_min = -0.9598657488822937, x_max = 11.166107177734375, y_min = 43.48225784301758, y_max = 60.700279235839844. Class = 0. Rotated = False.,\n",
              " Mnist Box: x_min = -0.7043758630752563, x_max = 11.24692440032959, y_min = 51.493831634521484, y_max = 68.75166320800781. Class = 0. Rotated = False.,\n",
              " Mnist Box: x_min = -0.5438572764396667, x_max = 9.265031814575195, y_min = -0.201450377702713, y_max = 12.6256742477417. Class = 0. Rotated = True.]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_CANVAS[0].plot()"
      ],
      "metadata": {
        "id": "adxe668LGxPr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}